{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "353ece44",
   "metadata": {},
   "source": [
    "## ğŸ“˜ **Topic 08: Pipeline in Polynomial Regression**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  What is a Pipeline?\n",
    "\n",
    "A **Pipeline** is a way to **chain together preprocessing steps and modeling steps** into one clean object. It helps:\n",
    "\n",
    "* Keep code clean\n",
    "* Avoid data leakage\n",
    "* Make hyperparameter tuning easier\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Why use it for Polynomial Regression?\n",
    "\n",
    "Polynomial Regression involves:\n",
    "\n",
    "1. Creating polynomial features (non-linear transformation)\n",
    "2. Fitting a linear regression model\n",
    "\n",
    "With a pipeline, you combine both steps into one line.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”§ Step-by-Step: Polynomial Pipeline\n",
    "\n",
    "### ğŸ“¦ Step 1: Import Libraries\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Š Step 2: Create Dataset\n",
    "\n",
    "```python\n",
    "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9]).reshape(-1, 1)\n",
    "y = np.array([3, 6, 8, 11, 15, 21, 30, 38, 50])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”§ Step 3: Build the Pipeline\n",
    "\n",
    "```python\n",
    "# Create pipeline: PolynomialFeatures â†’ LinearRegression\n",
    "poly_pipeline = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=2)),\n",
    "    ('linear_regression', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "poly_pipeline.fit(X, y)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ˆ Step 4: Predict and Plot\n",
    "\n",
    "```python\n",
    "# Predict\n",
    "y_pred = poly_pipeline.predict(X)\n",
    "\n",
    "# Plot\n",
    "plt.scatter(X, y, color='blue', label='Actual')\n",
    "plt.plot(X, y_pred, color='red', label='Polynomial Fit')\n",
    "plt.title(\"Polynomial Regression with Pipeline\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ” Step 5: Try Different Degrees with Pipeline\n",
    "\n",
    "```python\n",
    "for degree in [1, 2, 3, 4]:\n",
    "    pipeline = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=degree)),\n",
    "        ('model', LinearRegression())\n",
    "    ])\n",
    "    pipeline.fit(X, y)\n",
    "    y_pred = pipeline.predict(X)\n",
    "    \n",
    "    plt.scatter(X, y, color='blue')\n",
    "    plt.plot(X, y_pred, label=f'Degree {degree}')\n",
    "    plt.title(f'Polynomial Regression (Degree {degree})')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Benefits of Pipelines:\n",
    "\n",
    "* Clean, readable code\n",
    "* Avoids repetitive code\n",
    "* Ready for model tuning (e.g., `GridSearchCV`)\n",
    "* Keeps feature transformation and model tightly connected\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‰ Youâ€™ve Now Covered:\n",
    "\n",
    "âœ… Simple & Multiple Linear Regression\n",
    "âœ… Cost, Gradient Descent, Overfitting\n",
    "âœ… Polynomial Regression & Pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9e6bfd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
